{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1eff0c9",
   "metadata": {},
   "source": [
    "### Import and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5bb800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc1/Ubuntu/Extend_Data/em_Thanh/medrag_colpali/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from colpali_engine import ColPali, ColPaliProcessor\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598a50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_HOME\"] = \"/media/pc1/Ubuntu/Extend_Data/hf_models\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "dataset = load_dataset(\"davanstrien/ufo-ColPali\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2fd1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'raw_queries', 'broad_topical_query', 'broad_topical_explanation', 'specific_detail_query', 'specific_detail_explanation', 'visual_element_query', 'visual_element_explanation', 'parsed_into_json'],\n",
       "    num_rows: 2243\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfeca0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[29][\"image\"].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496af050",
   "metadata": {},
   "source": [
    "### Connecting to Qdrant server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7db089",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2969158",
   "metadata": {},
   "source": [
    "### Setup Colpali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb923da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 54827.50it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_name = (\n",
    "    \"davanstrien/finetune_colpali_v1_2-ufo-4bit\"\n",
    ")\n",
    "\n",
    "colpali_model = ColPali.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\"\n",
    ")\n",
    "\n",
    "colpali_processor = ColPaliProcessor.from_pretrained(\"vidore/colpaligemma-3b-pt-448-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee7e5a",
   "metadata": {},
   "source": [
    "### Configure Qdrant Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e4bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"ufo-binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f87d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    on_disk_payload=True,  # store the payload on disk\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=128,\n",
    "        distance=models.Distance.COSINE,\n",
    "        on_disk=True, # move original vectors to disk\n",
    "        multivector_config=models.MultiVectorConfig(\n",
    "            comparator=models.MultiVectorComparator.MAX_SIM\n",
    "        ),\n",
    "        quantization_config=models.BinaryQuantization(\n",
    "        binary=models.BinaryQuantizationConfig(\n",
    "            always_ram=True  # keep only quantized vectors in RAM\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c09bc",
   "metadata": {},
   "source": [
    "### Uploading to the Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10ed7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stamina\n",
    "\n",
    "@stamina.retry(on=Exception, attempts=3)\n",
    "def upsert_to_qdrant(points):\n",
    "    try:\n",
    "        client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points,\n",
    "            wait=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during upsert {e}\")\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ebe263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Progress: 2256it [06:34,  5.72it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16  # Adjust based on your GPU memory constraints\n",
    "\n",
    "# Use tqdm to create a progress bar\n",
    "with tqdm(total=len(dataset), desc=\"Indexing Progress\") as pbar:\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i : i + batch_size]\n",
    "\n",
    "        # The images are already PIL Image objects, so we can use them directly\n",
    "        images = batch[\"image\"]\n",
    "\n",
    "        # Process and encode images\n",
    "        with torch.no_grad():\n",
    "            batch_images = colpali_processor.process_images(images).to(\n",
    "                colpali_model.device\n",
    "            )\n",
    "            image_embeddings = colpali_model(**batch_images)\n",
    "\n",
    "        # Prepare points for Qdrant\n",
    "        points = []\n",
    "        for j, embedding in enumerate(image_embeddings):\n",
    "            # Convert the embedding to a list of vectors\n",
    "            multivector = embedding.cpu().float().numpy().tolist()\n",
    "            points.append(\n",
    "                models.PointStruct(\n",
    "                    id=i + j,  # we just use the index as the ID\n",
    "                    vector=multivector,  # This is now a list of vectors\n",
    "                    payload={\n",
    "                        \"source\": \"internet archive\"\n",
    "                    },  # can also add other metadata/data\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Upload points to Qdrant\n",
    "        try:\n",
    "            upsert_to_qdrant(points)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during upsert: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(batch_size)\n",
    "\n",
    "print(\"Indexing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc0c72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.update_collection(\n",
    "    collection_name=collection_name,\n",
    "    optimizer_config=models.OptimizersConfigDiff(indexing_threshold=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e4e7f",
   "metadata": {},
   "source": [
    "### process query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "534f851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1543, -0.0261,  0.0933,  ..., -0.0112, -0.0762, -0.0381],\n",
       "         [ 0.0425, -0.0718, -0.0120,  ...,  0.1211, -0.0645,  0.0659],\n",
       "         [ 0.0762,  0.0330,  0.0762,  ..., -0.0249, -0.0173,  0.0182],\n",
       "         ...,\n",
       "         [-0.0013,  0.0554,  0.0452,  ...,  0.0023,  0.0547,  0.0620],\n",
       "         [ 0.0369,  0.0425,  0.0332,  ...,  0.0162,  0.0583,  0.0669],\n",
       "         [ 0.1196,  0.0564,  0.0718,  ..., -0.0063,  0.0112,  0.0732]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text = \"top secret\"\n",
    "with torch.no_grad():\n",
    "    batch_query = colpali_processor.process_queries([query_text]).to(\n",
    "        colpali_model.device\n",
    "    )\n",
    "    query_embedding = colpali_model(**batch_query)\n",
    "query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "266c8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivector_query = query_embedding[0].cpu().float().numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f64d7ac",
   "metadata": {},
   "source": [
    "### searching and retrieving document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f791b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search completed in 0.0088 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "search_result = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=multivector_query,\n",
    "    limit=5,\n",
    "    timeout=100,\n",
    "    search_params=models.SearchParams(\n",
    "        quantization=models.QuantizationSearchParams(\n",
    "            ignore=False,\n",
    "            rescore=True,\n",
    "            oversampling=2.0,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "end_time = time.time()\n",
    "# Search in Qdrant\n",
    "search_result.points\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Search completed in {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7194173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "idx = search_result.points[0].id\n",
    "dataset[idx][\"image\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b94117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medrag-colpali",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
